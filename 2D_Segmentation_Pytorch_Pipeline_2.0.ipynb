{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4T4PTKzqV7r"
      },
      "source": [
        "#  **Colab File for CNN training- *PyTorch***\n",
        "Before you start please prepare the following:\n",
        "\n",
        "\n",
        "1.   Uplaod the dataset as Zip file to GDrive\n",
        "2.   Upload code files to GDrive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anuPzNOrt6MG"
      },
      "source": [
        "**Please MAKE sure that you are using GPU . Go to Runtime>> Change Runtime type  and select GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bTtSX5Wm_YB"
      },
      "source": [
        "#  **Connect to Google Drive**\n",
        " Allow Google Colab to connect to your GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHbwgC6Q7fBo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s0cNjAMnKX8"
      },
      "source": [
        "2- Change directory to where you want to keep your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHv-xVbxkIE0"
      },
      "source": [
        "3 - Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVKz0FvEQmHg"
      },
      "outputs": [],
      "source": [
        "# Download Dataset\n",
        "from IPython.display import clear_output\n",
        "# !pip install --upgrade --no-cache-dir gdown\n",
        "#!gdown 1oKH1urVUELrrnQfDTPDt4Aj5H3NwNzn6 #0.4451, 0.4431, 0.4012 - 0.2162, 0.2093, 0.2245\n",
        "!gdown 1swRiQZRCU3tjYotRIfdWSqSVVGN9RCoa\n",
        "\n",
        "!jar xvf 'Data.zip'\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkc20ppNQunv"
      },
      "outputs": [],
      "source": [
        "!rm -r 'Data.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02TG3nUZkKIM"
      },
      "source": [
        "4 - Download Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5h0PGlEdEEB",
        "outputId": "1ad29cd0-dac2-4b70-adce-1752412f9ab3"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkQJok4yXweC"
      },
      "outputs": [],
      "source": [
        "#!gdown --id 1GJc1zBMaY5tirewUOrKQcGv43SoaIVWS #1.6\n",
        "!gdown 1rE78950bEEQd_1WZ80TUXPwcFj-zSyhV #2.0\n",
        "!jar xvf '2D_Segmentation.zip'\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIv3dVlzXxmG"
      },
      "outputs": [],
      "source": [
        "!rm -r '2D_Segmentation.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qW6Kr8h8_Yt"
      },
      "source": [
        "# Install and Import Required Libraries (Conditionally Optional)\n",
        "Use 'pip' to install libraries. Put '!' i.e. Exclamation Mark before each command, exclusive to Jupyter Notebooks. Some are already installed by Google Colab and others are required. If the IMPORT statements are present in the python code being run, no need to follow this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwcSKqE1Ynvf"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "#!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "clear_output() #comment out to debug\n",
        "\n",
        "# CudaVersion = !nvcc --version\n",
        "# CudaVersion = CudaVersion[3].partition('V')[2][0:4]\n",
        "# if CudaVersion == '11.0':\n",
        "#   # CUDA 11.0\n",
        "#   !pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# elif CudaVersion == '10.2':\n",
        "#   # CUDA 10.2\n",
        "#   !pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
        "# elif CudaVersion == '10.1':\n",
        "#   # CUDA 10.1\n",
        "#   !pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# else:\n",
        "#   # CUDA 9.2\n",
        "#   !pip install torch==1.7.1+cu92 torchvision==0.8.2+cu92 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t3fpBO1Im3R"
      },
      "outputs": [],
      "source": [
        "# !pip install torch\n",
        "# !pip install torchvision\n",
        "# !pip install torchsummary\n",
        "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install -U scikit-learn\n",
        "!pip install scikit-image\n",
        "!pip install ipython\n",
        "\n",
        "!pip install Pillow\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install gdown\n",
        "\n",
        "!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "!pip install segmentation-models-pytorch\n",
        "clear_output() #comment out to debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMaUgR199h58"
      },
      "outputs": [],
      "source": [
        "# Printing out all outputs\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "# PyTorch\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from torch import optim, cuda, tensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "# warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "# Data science tools\n",
        "import numpy as np\n",
        "import os\n",
        "from os import path\n",
        "from importlib import import_module\n",
        "# Visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.size'] = 14\n",
        "# customized functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m_ORJ3F8RO6"
      },
      "source": [
        "# GPU Checking (Optional)\n",
        "Check the available GPU from the Google Server, GPU model and other related information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xskExVE68poJ",
        "outputId": "043722b6-32e6-4fb1-dd57-175fbcbc0e93"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Is CUDA enabled GPU Available?\", torch.cuda.is_available())\n",
        "print(\"Is GPU Initialized yet?\", torch.cuda.is_initialized())\n",
        "print(\"GPU Number:\", torch.cuda.device_count())\n",
        "print(\"Current GPU Index:\", torch.cuda.current_device())\n",
        "print(\"GPU Type:\", torch.cuda.get_device_name(device=None))\n",
        "print(\"GPU Capability:\", torch.cuda.get_device_capability(device=None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6OYtPdk7hkN"
      },
      "source": [
        "# Available Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFTfXwNA7gbt"
      },
      "source": [
        "**SMP Loss List:**\n",
        "\n",
        "https://smp.readthedocs.io/en/latest/losses.html\n",
        "\n",
        "**SMP Encoder List:**\n",
        "\n",
        "https://smp.readthedocs.io/en/latest/encoders.html\n",
        "\n",
        "https://smp.readthedocs.io/en/latest/encoders_timm.html\n",
        "\n",
        "**SMP Decoder List:**\n",
        "\n",
        "https://smp.readthedocs.io/en/latest/models.html\n",
        "\n",
        "**Additional Decoders**\n",
        "\n",
        "* 'Unet3Plus'\n",
        "\n",
        "**ONN-Based Decoders**\n",
        "\n",
        "* 'SelfONN_Unet'\n",
        "\n",
        "* 'SelfONN_UnetPlusPlus'\n",
        "\n",
        "* 'SelfONN_ResUnet'\n",
        "\n",
        "* 'SelfONN_FPN'\n",
        "\n",
        "**Custom Models**\n",
        "\n",
        "* 'UNet'\n",
        "\n",
        "* 'M_UNet'\n",
        "\n",
        "* 'UNet_2Plus'\n",
        "\n",
        "* 'UNet_3Plus'\n",
        "\n",
        "* 'MultiResUNet'\n",
        "\n",
        "* 'CSNet'\n",
        "\n",
        "* 'Self_UNet'\n",
        "\n",
        "* 'SelfUNet_compact'\n",
        "\n",
        "* 'SelfUNet_super_compact'\n",
        "\n",
        "* 'Super_FPN'\n",
        "\n",
        "* 'Attention_Super_FPN'\n",
        "\n",
        "* 'SA_UNet'\n",
        "\n",
        "* 'ACC_UNet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ModqLdS2jhjy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYnz-wSso9Pi"
      },
      "source": [
        "# **Model Training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-class Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdLdnTg1xcYa",
        "outputId": "e2994ac4-b34c-404a-8cd7-0d63a3d98515"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "#palette = [155, 38, 182, 14, 135, 204, 124, 252, 0, 255, 20, 147, 169, 169, 169, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15]\n",
        "palette = [0,0,0,71,39,119,62,73,137,48,103,141,37,130,142,30,157,136,53,183,120,109,206,88,181,221,43,253,231,36]\n",
        "images_location = r'/content/Data/Train'\n",
        "\n",
        "max_train = 2000\n",
        "\n",
        "transformations = A.Compose([\n",
        "    #A.Rotate(limit = [30,30],p=1,border_mode=cv2.BORDER_CONSTANT),\n",
        "    #A.VerticalFlip(p = 0.5),\n",
        "    #A.Resize(height, width, interpolation=cv2.INTER_AREA, always_apply=False, p=1),\n",
        "    A.HorizontalFlip(p = 0.5),\n",
        "    A.Affine(translate_percent = {'y' : (-0.3, -0.1)}, p = 1,mode=cv2.BORDER_CONSTANT),\n",
        "    #A.Affine(translate_percent = {'y' : (-0.05, 0.05)}, p = 1,mode=cv2.BORDER_CONSTANT),\n",
        "    A.Affine(translate_percent = {'x' : (-0.05, 0.05)}, p = 0.5,mode=cv2.BORDER_CONSTANT),\n",
        "    A.Affine(shear = [-2,2], p = 0.5, mode=cv2.BORDER_CONSTANT),\n",
        "    A.Rotate(limit = [-20,20],p=1, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.Affine(scale = (0.95, 1.05), p = 0.5, keep_ratio = True, mode=cv2.BORDER_CONSTANT),\n",
        "\n",
        "    #A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.05, rotate_limit=10, border_mode=cv2.BORDER_CONSTANT,always_apply=False,p=1),\n",
        "    #A.Affine(shear = [30,30], p = 0.5, mode=cv2.BORDER_REFLECT_101),\n",
        "    #A.RandomGridShuffle (grid=(2, 2), always_apply=False, p = 0.5),\n",
        "    #A.RandomScale(scale_limit=0.1, interpolation=cv2.INTER_CUBIC, always_apply=False, p=1)\n",
        "])\n",
        "\n",
        "for folds in os.listdir(images_location):\n",
        "\n",
        "  fold_path = os.path.join(images_location, folds)\n",
        "  image_list  = os.listdir(os.path.join(fold_path,\"images\"))\n",
        "  image_list = np.random.choice(image_list, int(len(image_list)), replace = False)\n",
        "  remain_image = max_train - int(len(image_list))\n",
        "\n",
        "  for i in tqdm(range(remain_image)):\n",
        "\n",
        "    image_name = image_list[i % len(image_list)]\n",
        "    image_path = os.path.join(fold_path,\"images\",image_name)\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    mask_name = image_name\n",
        "    mask_path = os.path.join(fold_path,\"masks\",mask_name)\n",
        "    mask = Image.open(mask_path)\n",
        "    mask = np.array(mask)\n",
        "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    transformed = transformations(image = image, mask = mask)\n",
        "    processed_image = transformed['image']\n",
        "    processed_mask = transformed['mask']\n",
        "\n",
        "    file_name = os.path.join(fold_path,\"images\",image_name[:-4]+f'_aug{i}.png')\n",
        "\n",
        "    cv2.imwrite(file_name, processed_image)\n",
        "\n",
        "\n",
        "    file_name = os.path.join(fold_path,\"masks\",image_name[:-4]+f'_aug{i}.png')\n",
        "\n",
        "\n",
        "    processed_mask = Image.fromarray(processed_mask)\n",
        "\n",
        "    processed_mask = processed_mask.convert('P')\n",
        "\n",
        "    processed_mask.putpalette(palette)\n",
        "\n",
        "    processed_mask.save(file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTHVVmY-zHbz",
        "outputId": "5fb85333-83f1-4689-bb3d-a95315845450"
      },
      "outputs": [],
      "source": [
        "# Dependencies directory\n",
        "%cd /content/2D_Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUHuT2yIcPLN"
      },
      "outputs": [],
      "source": [
        "from image_mean_std import cal_dir_stat\n",
        "in_channel_num = 3\n",
        "image_dir = '/content/Data/Train/fold_1/images'\n",
        "\n",
        "mean, std = cal_dir_stat(image_dir, in_channel_num)\n",
        "print(f'mean: {mean}\\n', f'std: {std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw8UGUOQ37fL",
        "outputId": "e33721d2-154b-48ea-8bbc-83d27cfb87ad"
      },
      "outputs": [],
      "source": [
        "%%writefile config.py\n",
        "# CNN configuration file\n",
        "\n",
        "##### DO NOT EDIT THESE LINES #####\n",
        "config = {}\n",
        "###################################\n",
        "\n",
        "\n",
        "#### START EDITING FROM HERE ######\n",
        "config['parentdir'] = '/content/'                                                        # main directory\n",
        "config['ONN'] = False                                                                     # set to 'True' if you are using ONN\n",
        "config['batch_size'] = 16                                                                # batch size, Change to fit hardware\n",
        "config['in_channels'] = 1                                                                # 1 for gray scale x-rays, and 3 for RGB (3channel) x-rays\n",
        "config['out_channels'] = 5                                                               # number of classes (Use 1 for binary, Use total number of classes with background for multiclass)\n",
        "config['palette'] = [0,0,0,71,39,119,62,73,137,48,103,141,37,130,142,30,157,136,53,183,120,109,206,88,181,221,43,253,231,36]\n",
        "config['disregard_background'] = True                                                    # For Multi-Class Only : Whether to Disregard Background (0 Class) in metric calculation\n",
        "config['input_mean'] = [0.1455]                                             # provide 3 numbers for RGB images or 1 number for gray scale images in list format\n",
        "config['input_std'] = [0.1797]                                             # provide 3 numbers for RGB images or 1 number for gray scale images in list format\n",
        "config['optim_fc'] = 'Adam'                                                              # 'Adam' or 'SGD'\n",
        "config['lr'] = 1e-3                                                                      # learning rate\n",
        "config['class_weights'] = None                                                           # class weights for multi class masks, default: none\n",
        "config['lossType'] = 'SMP_DiceLoss'                                                          # loss function: 'CrossEntropy' for multi-class. 'BCELoss' or 'DiceLoss' for binary class\n",
        "config['n_epochs']  = 100                                                               # number of training epochs\n",
        "config['epochs_patience'] = 5                                                            # if val loss did not decrease for a number of epochs then decrease learning rate by a factor of lr_factor\n",
        "config['lr_factor'] = 0.2\n",
        "config['max_epochs_stop'] = 20                                                            # maximum number of epochs with no improvement in validation loss for early stopping\n",
        "config['num_folds']  = 1                                                                 # number of cross validation folds\n",
        "config['Resize_h'] = 256                                                                 # network input size\n",
        "config['Resize_w'] = config['Resize_h']\n",
        "# config['load_model'] = config['parentdir'] + 'load_model/Densenet121_FPN_lung_seg_fold_1.pt'    # specify path of pretrained model wieghts or set to False to train from scratch\n",
        "config['load_model'] = False                                                             # specify path of pretrained model wieghts or set to False to train from scratch\n",
        "config['Test_Mask'] = True                                                               # set to true if you have the test masks, to compute Evaluation metricies over test set\n",
        "config['model_type'] = 'Custom'                                                             # SMP libary models : SMP | ONN-Based Decoders : ONN_dec | Custom models : Custom\n",
        "config['model_to_load'] = 'UNet'                                     # enter model name like this: <encoder_name>*<decoder_name> (names should match the documentation exactly)\n",
        "config['model_name'] = 'MulticlassTest_Promit_UNet'                              # choose a unique name for result folder\n",
        "config['decoder_attention'] = None                                                  # Turn on Attention Layer in Unet/Unet++ (None / 'scse') (only works with SMP and ONN_dec)\n",
        "config['encoder_depth']  = 5                                                            # number of encoder layers (For pretrained weights default: 5) (not usable with PAN decoder)\n",
        "config['encoder_weights'] = 'imagenet'                                                  # pretrained weights: 'imagenet' | Train from scratch: None (some encoders have multiple weights check documentation)\n",
        "config['activation'] = None                                                             # last layer activation function (default: None | Available functions: provided in the list above)\n",
        "config['q_order'] = 3                                                                    # ONN q-order\n",
        "config['max_shift'] = 0                                                                  # ONN max_shift\n",
        "config['seg_threshold'] = 0.5                                                           # Segmentation Threshold (Default 0.5)\n",
        "config['U_init_features'] = 32                                                           # Only for model_type : Custom | number of kernals in the first UNet conv layer ('32' & '64' are common values)\n",
        "config['fold_to_run'] = [1,1] # define as [] to loop through all folds, or specify start and end folds i.e. [3, 5] or [5, 5]\n",
        "config['Results_path'] = \"/content/drive/MyDrive/Rusab/Multiclass_test/\" + \"Results\"   # main results file\n",
        "config['save_path'] = config['Results_path'] +'/'+ config['model_name']                  # save path\n",
        "config['generated_masks']  =  '/content/drive/MyDrive/Rusab/Multiclass_test/' + 'Generated_mask'         # path to save generated_masks for test set\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvNDFdH-DLTX"
      },
      "source": [
        "2- Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmrBOvFpb6kD"
      },
      "outputs": [],
      "source": [
        "#!rm -r /content/Data/Val/fold_1/.ipynb_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwiHtfxXkv9g",
        "outputId": "0cdc7c82-3b1a-4c4e-c3e8-ead0a288c906"
      },
      "outputs": [],
      "source": [
        "!python TrainUnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpDdx34PZJ6Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Su3tl0Jd8_i"
      },
      "source": [
        "3-Custom evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3UNyR2a5K0-"
      },
      "outputs": [],
      "source": [
        "import metric_evaluation_opt\n",
        "gnd = '/content/Data/Test'\n",
        "predict = '/content/drive/MyDrive/Rusab/Multiclass_test/Generated_mask/BinaryclassTest_Carotid_resnet18*SelfONN_Unet'\n",
        "class_map = []\n",
        "metric_evaluation_opt.evaluation(gnd, predict, save = True, reduction = 'micro', classes = 1, class_map = class_map, disregard_background = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRXh2KZypNUm"
      },
      "source": [
        "#**Run your model on an exteranl dataset or re-generate the test results**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzlGH05rXv7m",
        "outputId": "70f5208f-6a6d-403f-eb51-98aba1cf7b8a"
      },
      "outputs": [],
      "source": [
        "%cd /content/2D_Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaRgIvrE5vcA",
        "outputId": "afb328fd-cd86-4261-ede7-8d7906b3418e"
      },
      "outputs": [],
      "source": [
        "#/content/drive/MyDrive/Rusab/Coronary_segmentation/\n",
        "%%writefile config_test.py\n",
        "# CNN test configuration file\n",
        "\n",
        "##### DO NOT EDIT THESE LINES #####\n",
        "config = {}\n",
        "###################################\n",
        "\n",
        "#### START EDITING FROM HERE ######\n",
        "config['parentdir'] = '/content/'                                                        # main directory\n",
        "config['ONN'] = True                                                                     # set to 'True' if you are using ONN\n",
        "config['batch_size'] = 16                                                                # batch size, Change to fit hardware\n",
        "config['in_channels'] = 3                                                                # 1 for gray scale x-rays, and 3 for RGB (3channel) x-rays\n",
        "config['out_channels'] = 5                                                               # number of classes (Use 1 for binary, Use total number of classes with background for multiclass)\n",
        "config['palette'] = [155, 38, 182, 14, 135, 204, 124, 252, 0, 255, 20, 147, 169, 169, 169, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15]\n",
        "config['disregard_background'] = False                                                    # For Multi-Class Only : Whether to Disregard Background (0 Class) in metric calculation\n",
        "config['input_mean'] = [0.4451, 0.4431, 0.4012]                                             # provide 3 numbers for RGB images or 1 number for gray scale images in list format\n",
        "config['input_std'] = [0.2162, 0.2093, 0.2245]                                             # provide 3 numbers for RGB images or 1 number for gray scale images in list format\n",
        "config['num_folds'] = 1                                                                  # number of folds\n",
        "config['class_weights'] = None                                                           # class weights for multi class masks, default: none\n",
        "config['lossType'] = 'SMP_DiceLoss'\n",
        "config['Resize_h'] = 256                                                                 # network input size\n",
        "config['Resize_w'] = config['Resize_h']\n",
        "# config['load_model'] = '/content/drive/Shareddrives/Rusab/Coronary_Angiogram/Results/MixTrain_densenet121*SelfONN_ResUnet/MixTrain_densenet121*SelfONN_ResUnet_fold_3.pt'        # specify full path of pretrained model pt file\n",
        "config['load_model'] = False                                                             # specify path of pretrained model wieghts or set to False to train from scratch\n",
        "config['Test_Mask'] = True                                                               # set to true if you have the test masks, to compute Evaluation metricies over test set\n",
        "config['model_name'] = 'MulticlassTest_UNet_sanity'            # choose a unique name for result folder\n",
        "config['decoder_attention'] = 'scse'                                                   #decoder attention type\n",
        "config['seg_threshold'] = 0.5                                                           # Segmentation Threshold (Default 0.5)\n",
        "config['new_name'] = 'MulticlassTest_UNet_sanity'                                                                 #specify a new folder name to save test results,\n",
        "config['fold_to_run'] = [1,1] # define as [] to loop through all folds, or specify start and end folds i.e. [3, 5] or [5, 5]     # else set to False to overwrite test results genertaed by train code\n",
        "##################\n",
        "\n",
        "##################\n",
        "config['generated_masks']  = \"/content/drive/MyDrive/Rusab/Multiclass_test/\" + 'Generated_mask'        # path to save generated_masks for test set\n",
        "config['Results_path'] = \"/content/drive/MyDrive/Rusab/Multiclass_test/\" + \"Results\"                      # main results file\n",
        "if config['new_name']:\n",
        "    config['save_path'] = config['Results_path'] +'/'+ config['new_name']                                      # new save path\n",
        "else:\n",
        "    config['save_path'] = config['Results_path'] +'/'+ config['model_name']                                    # same save path used for training\n",
        "##################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ48T8byjw16"
      },
      "source": [
        "Test on Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEE4rWb96FXt",
        "outputId": "78a92c2e-8626-47ec-bb1d-6051ceabdb61"
      },
      "outputs": [],
      "source": [
        "!python TestUnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import metric_evaluation_opt\n",
        "gnd = '/content/Data/Test'\n",
        "predict = '/content/drive/MyDrive/Rusab/Multiclass_test/Generated_mask/BinaryclassTest_Carotid_resnet18*SelfONN_Unet'\n",
        "class_map = []\n",
        "metric_evaluation_opt.evaluation(gnd, predict, save = True, reduction = 'micro', classes = 1, class_map = class_map, disregard_background = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9O4LnpUjycs"
      },
      "source": [
        "Colorize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-imZn9vuzlwp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: colorize_evaluation.py [-h] --gt GT --pred PRED --des DES [--type TYPE]\n",
            "colorize_evaluation.py: error: unrecognized arguments: Works\\DroneData_Kaggle\\Promit\\v1.1.1\\Data\\Test\\fold_1\\masks Works\\DroneData_Kaggle\\Promit\\Generated_Masks\\MulticlassTest_Promit_densenet121_SelfONN_Unet/fold_1 Works\\DroneData_Kaggle\\Promit\\Generated_Masks\\MulticlassTest_Promit_densenet121_SelfONN_Unet/compare/fold_1\n"
          ]
        }
      ],
      "source": [
        "seg_type = 'binary' #'multiclass' for multiclass\n",
        "predict_dir = '/content/drive/MyDrive/Coronary_Angiogram/colabpro3/Generated_mask/FinalOldMask_mit_b1*FPN'\n",
        "color_output_dir = predict_dir + '/compare'\n",
        "\n",
        "for i in range(1,6):\n",
        "  gnd = '/content/Data/Test/fold_'+ str(i) +'/masks'\n",
        "  predict = predict_dir + '/fold_' + str(i)\n",
        "  des = color_output_dir  + '/fold_'+ str(i)\n",
        "  \n",
        "\n",
        "  !python colorize_evaluation.py --gt $gnd --pred $predict --des $des --type $seg_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "72c040cb0d415db2c05e3e4f3fbc60605e9549341fae5cd5d6069294930dd723"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
